type: agent
name: nexau_code_agent
max_context_tokens: 100000
system_prompt: ./nexau-gemini-cli-systemprompt.md
system_prompt_type: jinja
tool_call_mode: openai # xml, openai or anthorpic
max_iterations: 300
llm_config: # Support environment variable replacement in YAML config
  model: ${env.LLM_MODEL}
  base_url: ${env.LLM_BASE_URL}
  api_key: ${env.LLM_API_KEY}
  temperature: 0.7
  stream: False
  api_type: openai_chat_completion # support openai_chat_completion (default), openai_responses (especially for gpt-5-codex), anthropic_chat_completion
tools: # Tool implementations based on gemini-cli (local Python implementations)
  # File operations - read_file, write_file, replace
  - name: read_file
    yaml_path: ./tools/read_file.tool.yaml
    binding: nexau_harbor.tool_impl.read_file:read_file
  - name: write_file
    yaml_path: ./tools/write_file.tool.yaml
    binding: nexau_harbor.tool_impl.write_file:write_file
  - name: replace
    yaml_path: ./tools/replace.tool.yaml
    binding: nexau_harbor.tool_impl.replace:replace
  # Search and navigation - search_file_content, glob, list_directory
  - name: search_file_content
    yaml_path: ./tools/search_file_content.tool.yaml
    binding: nexau_harbor.tool_impl.search_file_content:search_file_content
  - name: glob
    yaml_path: ./tools/glob.tool.yaml
    binding: nexau_harbor.tool_impl.glob_tool:glob
  - name: list_directory
    yaml_path: ./tools/list_directory.tool.yaml
    binding: nexau_harbor.tool_impl.list_directory:list_directory
  # Shell command
  - name: run_shell_command
    yaml_path: ./tools/run_shell_command.tool.yaml
    binding: nexau_harbor.tool_impl.run_shell_command:run_shell_command
  # Web tools - google_web_search, web_fetch
  - name: google_web_search
    yaml_path: ./tools/google_web_search.tool.yaml
    binding: nexau_harbor.tool_impl.google_web_search:google_web_search
  - name: web_fetch
    yaml_path: ./tools/web_fetch.tool.yaml
    binding: nexau_harbor.tool_impl.web_fetch:web_fetch
  # Task management
  - name: write_todos
    yaml_path: ./tools/write_todos.tool.yaml
    binding: nexau_harbor.tool_impl.write_todos:write_todos
  # Batch file reading
  - name: read_many_files
    yaml_path: ./tools/read_many_files.tool.yaml
    binding: nexau_harbor.tool_impl.read_many_files:read_many_files
  # Task completion (mandatory termination protocol)
  - name: complete_task
    yaml_path: ./tools/complete_task.tool.yaml
    binding: nexau_harbor.tool_impl.complete_task:complete_task
middlewares:
  - import: nexau_harbor.complete_task_hook:CompleteTaskMiddleware
  # # Aggressive context compaction (no LLM summarization)
  # - import: nexau_harbor.compact_context_hook:AggressiveCompactContextMiddleware
  #   params:
  #     max_context_tokens: 50000
  #     compression_threshold: 0.3
  #     preserve_ratio: 0.2
  #     tool_output_token_budget: 10000
  #     truncate_lines: 20
  #     collapse_duplicate_tools: true
  # ============================================================
  # LLM State Snapshot Version (gemini-cli style <state_snapshot>)
  # Uncomment below and comment out AggressiveCompactContextMiddleware above
  # to enable LLM-powered context summarization
  # ============================================================
  # - import: nexau_harbor.compact_context_hook:StateSnapshotCompactMiddleware
  #   params:
  #     max_context_tokens: 200000
  #     compression_threshold: 0.5      # Trigger at 50% (gemini-cli default)
  #     preserve_ratio: 0.3             # Preserve 30% recent history
  #     tool_output_token_budget: 50000 # 50k tokens per tool output
  #     truncate_lines: 30              # Last 30 lines
  #     llm_model: ${env.LLM_MODEL}     # Use same model as agent
  #     # llm_client is auto-configured from agent's llm_config
  # ============================================================
tracers:
  - import: nexau.archs.tracer.adapters.in_memory:InMemoryTracer
